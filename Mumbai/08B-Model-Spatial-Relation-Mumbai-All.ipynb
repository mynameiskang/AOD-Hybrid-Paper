{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from glob import glob\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "def extract_date_from_file_name(FILE_NAME):\n",
    "    return datetime.datetime.strptime(FILE_NAME.split('/')[-1].split('.')[1:][0][1:], \"%Y%j\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import configparser\n",
    "\n",
    "\n",
    "config = configparser.ConfigParser()\n",
    "config.read(\"./config.ini\")\n",
    "\n",
    "PATH = config['path']['hdf_path_2020'] + \"*\"\n",
    "FILE_LIST = glob(PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pkl_obj = pickle.load(open(\"mumbai_geodata.pkl\", \"rb\"))\n",
    "MUMBAI_B_MIN_LON, MUMBAI_B_MAX_LON = pkl_obj['min_lon'], pkl_obj['max_lon']\n",
    "MUMBAI_B_MIN_LAT, MUMBAI_B_MAX_LAT = pkl_obj['min_lat'], pkl_obj['max_lat']\n",
    "boundary = pkl_obj['boundary']\n",
    "mask = pkl_obj['mumbai_mask'] \n",
    "\n",
    "SDS_NAME = \"Optical_Depth_047\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.basemap import Basemap, cm\n",
    "\n",
    "def plot_mumbai_aod_map(name, scaled_data, date_time, save=False, should_mask=True):\n",
    "\n",
    "    add_text = \"\"\n",
    "    \n",
    "    plt.figure(figsize=(20, 10))\n",
    "\n",
    "    pad = 0.01\n",
    "\n",
    "    m = Basemap(projection='cyl', resolution='l', llcrnrlat=MUMBAI_B_MIN_LAT-pad, urcrnrlat=MUMBAI_B_MAX_LAT+pad, llcrnrlon=MUMBAI_B_MIN_LON-pad, urcrnrlon=MUMBAI_B_MAX_LON+pad , suppress_ticks=True)\n",
    "\n",
    "    m.readshapefile(\"../Municipal_Spatial_Data/Mumbai/Mumbai\",'Mumbai', linewidth=1)\n",
    "\n",
    "    m.drawparallels(np.arange(-90., 120., 0.05), labels=[1, 0, 0, 0], fontsize=16)\n",
    "    m.drawmeridians(np.arange(-180., 181., 0.05), labels=[0, 0, 0, 1],  fontsize=16)\n",
    "    x, y = m(mcd19a2_longitude[mask], mcd19a2_latitude[mask])\n",
    "\n",
    "    if should_mask:\n",
    "        sc = m.scatter(x, y, c=scaled_data[mask], s=250, cmap=plt.cm.jet,\n",
    "                        edgecolors='white', linewidth=0, marker='s')\n",
    "    else:\n",
    "        add_text = \"_interpolated\"\n",
    "        sc = m.scatter(x, y, c=scaled_data, s=250, cmap=plt.cm.jet,\n",
    "                        edgecolors='white', linewidth=0, marker='s')\n",
    "\n",
    "    cb = m.colorbar()\n",
    "    cb.set_label('AOD', size=18)\n",
    "    cb.ax.tick_params(labelsize=16)\n",
    "\n",
    "    plotTitle = name[:-4]\n",
    "    plt.title('{0}\\n {1}\\n Mumbai, India\\n {2}'.format(plotTitle, SDS_NAME, date_time.strftime(\"%Y-%m-%d\")), fontsize=24)\n",
    "    fig = plt.gcf()\n",
    "\n",
    "#     plt.show()\n",
    "    \n",
    "    if save:\n",
    "        pngfile = 'images/{0}{1}.png'.format(plotTitle, add_text)\n",
    "        fig.savefig(pngfile, bbox_inches=\"tight\", dpi=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hypotenuse_distance(x, y):\n",
    "    return np.sqrt(x**2 + y**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_predict(X, regressor, scaler):    \n",
    "    if scaler:\n",
    "        try:\n",
    "            sc_X, sc_y = scaler\n",
    "            y_pred = sc_y.inverse_transform(regressor.predict(sc_X.transform(X)))\n",
    "        except Exception as e:\n",
    "            poly_reg = scaler\n",
    "            y_pred = regressor.predict(poly_reg.transform(X))\n",
    "    else:\n",
    "        y_pred = regressor.predict(X)\n",
    "    distances = np.array(list(map(lambda x: hypotenuse_distance(x[1], x[2]), X)))\n",
    "    return np.array(list(zip(y_pred, distances)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weighted_value(y):\n",
    "    weights = 1 / pow(y[:,1], 2)\n",
    "    return sum(weights * y[:, 0]) / sum(weights)\n",
    "    \n",
    "def mix(y_list):\n",
    "    return np.array(list(map(lambda x: get_weighted_value(x), y_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nearest_3x3_grid(data, x, y):\n",
    "    \n",
    "    if x < 1:\n",
    "        x += 1\n",
    "    if x > data.shape[0]-2:\n",
    "        x -= 2\n",
    "    if y < 1:\n",
    "        y += 1\n",
    "    if y > data.shape[1]-2:\n",
    "        y -= 2  \n",
    "    \n",
    "    three_by_three = data[x-1:x+2,y-1:y+2]\n",
    "    three_by_three = three_by_three.astype(float)\n",
    "    \n",
    "    not_nans = np.count_nonzero(~np.isnan(three_by_three))\n",
    "    \n",
    "    if not_nans == 0:\n",
    "        return {\n",
    "            \"x\": x,\n",
    "            \"y\": y,\n",
    "        }\n",
    "    else:\n",
    "        three_by_three_average = np.nanmean(three_by_three)\n",
    "        three_by_three_std = np.nanstd(three_by_three)\n",
    "        three_by_three_median = np.nanmedian(three_by_three)\n",
    "        \n",
    "        return {\n",
    "            \"x\": x,\n",
    "            \"y\": y,\n",
    "            \"data\": three_by_three,\n",
    "            \"average\": three_by_three_average,\n",
    "            \"std\": three_by_three_std,\n",
    "            \"median\": three_by_three_median\n",
    "        }    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "MUMBAI_GEO_OBJ = pickle.load(open(\"./mumbai_geodata.pkl\", \"rb\"))\n",
    "MUMBAI_MASK = MUMBAI_GEO_OBJ['mumbai_mask']\n",
    "MUMBAI_COORDS = MUMBAI_GEO_OBJ['mumbai_coords']\n",
    "\n",
    "DECIMAL_PLACES = 7\n",
    "PROCESS_ML_DATA = True\n",
    "\n",
    "CITY = \"Mumbai\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "india_stations_df = pd.read_pickle('../2015-2020-pm25/india_stations.pkl')\n",
    "stations = india_stations_df[india_stations_df['City'] == CITY]['StationId'].values\n",
    "\n",
    "mcd19a2_obj = pickle.load(open(\"./mcd19a2.pkl\", \"rb\"))\n",
    "mcd19a2_longitude, mcd19a2_latitude = mcd19a2_obj['longitude'], mcd19a2_obj['latitude']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = \"spt_models\"\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyhdf import SD\n",
    "\n",
    "def perform_task(idx):\n",
    "    \n",
    "    empty_flag = 0\n",
    "    \n",
    "    FILE_NAME = FILE_LIST[idx]\n",
    "    NAME = FILE_NAME.split('/')[-1]\n",
    "    date_time = extract_date_from_file_name(FILE_NAME)\n",
    "    \n",
    "    # ------------------ Data Loading Begin -------------------------\n",
    "\n",
    "    hdf = SD.SD(FILE_NAME)\n",
    "    sds = hdf.select(SDS_NAME)\n",
    "    data = sds.get()\n",
    "\n",
    "    attributes = sds.attributes()\n",
    "    scale_factor = attributes['scale_factor']\n",
    "    fv = attributes['_FillValue']\n",
    "\n",
    "    data = data.astype(float)\n",
    "    data[data == fv] = np.nan\n",
    "    data = np.nanmean(data, axis=0)\n",
    "\n",
    "    scaled_data = data * scale_factor\n",
    "    \n",
    "    # ------------------ Data Loading End -------------------------\n",
    "\n",
    "    plot_mumbai_aod_map(NAME, scaled_data, date_time, save=True);\n",
    "    \n",
    "    # ------------------ Interpolation Begin -------------------------\n",
    "\n",
    "    y_sp_interpolate = []\n",
    "\n",
    "    for i, station_id in enumerate(stations):\n",
    "        best = pickle.load(open(f\"{model_dir}/{station_id}_spt.pkl\", \"rb\"))\n",
    "\n",
    "        fix_station_lat, fix_station_lon = best['station_id']['nearest_lat'], best['station_id']['nearest_lon']\n",
    "        x_coord = best['station_id']['x_coord']\n",
    "        y_coord = best['station_id']['y_coord']\n",
    "\n",
    "        regressor = best['regressor']\n",
    "        scaler = best['scaler']\n",
    "\n",
    "        try:\n",
    "            fix_station_aod = get_nearest_3x3_grid(scaled_data, x_coord, y_coord)['average'].round(3)\n",
    "            X_sp_interpolate_sub = np.array(list(zip([fix_station_aod for k in range(MUMBAI_COORDS.shape[0])],\n",
    "                             (fix_station_lat - MUMBAI_COORDS[:,0]),\n",
    "                             (fix_station_lon - MUMBAI_COORDS[:,1]),\n",
    "                            )\n",
    "                        ))\n",
    "\n",
    "            y_sp_interpolate_sub = model_predict(X_sp_interpolate_sub, regressor, scaler)\n",
    "            y_sp_interpolate.append(y_sp_interpolate_sub)\n",
    "        except KeyError :\n",
    "            pass\n",
    "        \n",
    "    try:\n",
    "        y_sp_interpolate = np.array(y_sp_interpolate)\n",
    "        y_sp_interpolate = y_sp_interpolate.transpose(1, 0, 2)\n",
    "        y_sp_interpolate = mix(y_sp_interpolate).round(3)\n",
    "        y_sp_interpolate = y_sp_interpolate.reshape(-1,1)\n",
    "        plot_mumbai_aod_map(NAME, y_sp_interpolate, date_time, save=True, should_mask=False);\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing as mp\n",
    "\n",
    "pool = mp.Pool(mp.cpu_count())\n",
    "\n",
    "pool.map(perform_task, [idx for idx in range(len(FILE_LIST))])\n",
    "pool.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
