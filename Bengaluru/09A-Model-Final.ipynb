{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import pickle\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "\n",
    "station_names = [file.split(\"/\")[-1][:5] for file in glob(\"./dl_models/*.pkl\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(46)\n",
    "train_stations = list(np.random.choice(station_names, size=6, replace=False))\n",
    "test_stations  = list(set(station_names) - set(train_stations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['KA004', 'KA003', 'KA006', 'KA007', 'KA009', 'KA011']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['KA002']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import configparser\n",
    "\n",
    "config = configparser.ConfigParser()\n",
    "config.read(\"./config.ini\")\n",
    "\n",
    "city = \"Bengaluru\"\n",
    "\n",
    "START_DATE = config['period']['test_start_date']\n",
    "END_DATE   = config['period']['test_end_date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "india_stations  = pd.read_csv(\"../2015-2020-pm25/india_stations-corrected.csv\")\n",
    "bengaluru_stations = india_stations[india_stations[\"StationId\"].isin(train_stations + test_stations)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lat_lng(station_id):\n",
    "    row = bengaluru_stations[bengaluru_stations['StationId'] == station_id]\n",
    "    return row['Latitude'].values[0], row['Longitude'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "SPATIAL_MODELS_DIR  = \"./spt_models/\"\n",
    "\n",
    "sequence = {\n",
    "    \"Machine Learning\" : {\n",
    "        \"dir\": \"./ml_models/\"\n",
    "    },\n",
    "    \"Deep Learning\" : {\n",
    "        \"dir\": \"./dl_models/\"\n",
    "    },\n",
    "    \"Statistical\" : {\n",
    "        \"dir\": \"./stat_models/\"\n",
    "    }\n",
    "}\n",
    "\n",
    "sequence_keys = list(sequence.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in range(len(train_stations)):\n",
    "    station = train_stations[idx]\n",
    "    \n",
    "    for sub_idx in range(len(sequence_keys)):\n",
    "        key = sequence_keys[sub_idx]\n",
    "        \n",
    "        if (idx == 0):\n",
    "            if (key == \"Machine Learning\"):\n",
    "                models = [file.split(\"/\")[-2] + \" Regression\" for file in glob(sequence[key][\"dir\"] + \"*/\")]\n",
    "            else:\n",
    "                models = [file.split(\"/\")[-2] for file in glob(sequence[key][\"dir\"] + \"*/\")]\n",
    "            for model in models:\n",
    "                sequence[key][model] = {\n",
    "                    \"aod_values\"   : {},\n",
    "                    \"predictions\"  : {}\n",
    "                }\n",
    "\n",
    "        for file in glob(sequence[key][\"dir\"] + \"*\" + \"/\" + station + \"_aod.pkl\"):\n",
    "            model = file.split(\"/\")[-2]\n",
    "            if (key == \"Machine Learning\"):\n",
    "                model += \" Regression\"\n",
    "            \n",
    "            aod_values  = pickle.load(open(file, \"rb\"))\n",
    "            predictions = pickle.load(open(sequence[key][\"dir\"] + station + \"_predictions.pkl\", \"rb\")) \n",
    "\n",
    "            aod_values = pd.DataFrame(aod_values, index=predictions.index.values, columns=['aod'])[START_DATE:END_DATE]\n",
    "            predictions = predictions[START_DATE:END_DATE]\n",
    "\n",
    "            sequence[key][model]['aod_values'][station]  = aod_values\n",
    "            sequence[key][model]['predictions'][station] = predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sequence = {}\n",
    "\n",
    "for idx in range(len(test_stations)):\n",
    "    station = test_stations[idx]\n",
    "    predictions = pickle.load(open(\"./ml_models/\" + station + \"_predictions.pkl\", \"rb\")) \n",
    "    test_sequence[station] = predictions[START_DATE:END_DATE]['Actual']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "dates = [datetime.datetime.utcfromtimestamp(date.tolist()/1e9) for date in predictions[START_DATE:END_DATE].index.values ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hypotenuse_distance(x, y):\n",
    "    return np.sqrt(x**2 + y**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weighted_value(y):\n",
    "    weights = 1 / pow(y[:,1], 2)\n",
    "    return sum(weights * y[:, 0]) / sum(weights)\n",
    "    \n",
    "def mix(y_list):\n",
    "    return np.array(list(map(lambda x: get_weighted_value(x), y_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_predict(X, regressor, scaler):    \n",
    "    if scaler:\n",
    "        try:\n",
    "            sc_X, sc_y = scaler\n",
    "            y_pred = sc_y.inverse_transform(regressor.predict(sc_X.transform(X)))\n",
    "        except Exception as e:\n",
    "            poly_reg = scaler\n",
    "            y_pred = regressor.predict(poly_reg.transform(X))\n",
    "    else:\n",
    "        y_pred = regressor.predict(X)\n",
    "    distances = np.array(list(map(lambda x: hypotenuse_distance(x[1], x[2]), X)))\n",
    "    return np.array(list(zip(y_pred, distances)))\n",
    "\n",
    "def aod2pm25_model_predict(X, regressor, scaler):    \n",
    "    if scaler:\n",
    "        try:\n",
    "            sc_X, sc_y = scaler\n",
    "            y_pred = sc_y.inverse_transform(regressor.predict(sc_X.transform(X)))\n",
    "        except Exception as e:\n",
    "            poly_reg = scaler\n",
    "            y_pred = regressor.predict(poly_reg.transform(X))\n",
    "    else:\n",
    "        y_pred = regressor.predict(X)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_STATION_COORDS = np.array([get_lat_lng(station_id) for station_id in test_stations])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing as mp\n",
    "\n",
    "manager = mp.Manager()\n",
    "scores  = manager.dict()\n",
    "results = manager.dict() \n",
    "\n",
    "for category in sequence.keys():\n",
    "    scores[category]  = manager.dict({})\n",
    "    results[category] = manager.dict({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyhdf import SD\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "\n",
    "def perform_task(category, model):\n",
    "\n",
    "    y_aod_predictions = []\n",
    "\n",
    "    for idx in range(len(dates)):\n",
    "\n",
    "        y_sp_interpolate = []\n",
    "\n",
    "        for sub_idx in range(len(train_stations)):\n",
    "            station_id = train_stations[sub_idx]\n",
    "\n",
    "            best = pickle.load(open(f\"{SPATIAL_MODELS_DIR}/{station_id}_spt.pkl\", \"rb\")) \n",
    "\n",
    "            fix_station_lat, fix_station_lon = best['station_id']['nearest_lat'], best['station_id']['nearest_lon']\n",
    "            x_coord = best['station_id']['x_coord']\n",
    "            y_coord = best['station_id']['y_coord']\n",
    "\n",
    "            regressor = best['regressor']\n",
    "            scaler = best['scaler']\n",
    "\n",
    "\n",
    "            # ------------------ Interpolation Begin -------------------------\n",
    "\n",
    "            fix_station_aod = sequence[category][model]['aod_values'][station_id]['aod'].values[idx]\n",
    "\n",
    "            X_sp_interpolate_sub = np.array(list(zip([fix_station_aod for k in range(TEST_STATION_COORDS.shape[0])],\n",
    "                                     (fix_station_lat - TEST_STATION_COORDS[:,0]),\n",
    "                                     (fix_station_lon - TEST_STATION_COORDS[:,1]),\n",
    "                                    )\n",
    "                                ))\n",
    "\n",
    "            y_sp_interpolate_sub = model_predict(X_sp_interpolate_sub, regressor, scaler)\n",
    "            y_sp_interpolate.append(y_sp_interpolate_sub)\n",
    "\n",
    "            # ------------------ Interpolation End -------------------------\n",
    "\n",
    "        y_sp_interpolate = np.array(y_sp_interpolate)\n",
    "        y_sp_interpolate = y_sp_interpolate.transpose(1, 0, 2)\n",
    "        y_sp_interpolate = mix(y_sp_interpolate).round(3)\n",
    "        y_sp_interpolate = y_sp_interpolate.reshape(-1,1).T\n",
    "        \n",
    "#         print(y_sp_interpolate.shape)\n",
    "\n",
    "        y_aod_predictions.append(y_sp_interpolate)\n",
    "\n",
    "    # ------------------ AOD to PM2.5 Begin ----------------------------\n",
    "\n",
    "    y_aod_predictions = np.array(y_aod_predictions)\n",
    "    y_aod_predictions = y_aod_predictions.reshape(y_aod_predictions.shape[0], len(test_stations))\n",
    "\n",
    "    aod2pm25_model = pickle.load(open(config['convert'][\"aod_pm25\"], \"rb\"))\n",
    "\n",
    "    y_pm25_predictions = aod2pm25_model_predict(y_aod_predictions.reshape(-1, 1), aod2pm25_model['regressor'], aod2pm25_model['scaler']).reshape(y_aod_predictions.shape[0], len(test_stations))\n",
    "\n",
    "    y_pred = y_pm25_predictions.reshape(-1, 1)\n",
    "\n",
    "    # ------------------ AOD to PM2.5 End- ----------------------------\n",
    "\n",
    "    # ------------------ Scores Begin ---------------------------------\n",
    "\n",
    "    y_test = np.array([])\n",
    "\n",
    "    for key in test_stations:\n",
    "        y_test = np.append(y_test, test_sequence[key].values)\n",
    "\n",
    "    y_test = y_test.reshape(-1, 1)\n",
    "\n",
    "    score = {\n",
    "            \"r2_score\": r2_score(y_test, y_pred),\n",
    "            \"mae\": mean_absolute_error(y_test, y_pred), \n",
    "            \"rmse\": np.sqrt(mean_squared_error(y_test, y_pred)),\n",
    "            \"mean\": np.mean(y_test)\n",
    "        }\n",
    "    \n",
    "    scores[category][model] = score\n",
    "    \n",
    "    results[category][model] = {\n",
    "        \"score\": score,\n",
    "        \"y_pred\": y_pred,\n",
    "        \"y_test\": y_test\n",
    "    }\n",
    "\n",
    "    # ------------------ Scores End ---------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = [(outer_key, inner_key) for outer_key in sequence.keys() for inner_key in sequence[outer_key].keys()]\n",
    "pairs = [(a, b) for a, b in pairs if not b in ['dir']]\n",
    "\n",
    "pool = mp.Pool(mp.cpu_count())\n",
    "pool.starmap(perform_task, [pairs[idx] for idx in range(len(pairs))])\n",
    "pool.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = dict(scores)\n",
    "for key in scores.keys():\n",
    "    scores[key] = dict(scores[key])\n",
    "    \n",
    "results = dict(results)\n",
    "for key in results.keys():\n",
    "    results[key] = dict(results[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "pickle.dump(results, open(\"final_results.pkl\", \"wb\"), protocol=4)\n",
    "pickle.dump(scores, open(\"final_scores.pkl\", \"wb\"), protocol=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "reform = {(outerKey, innerKey): values for outerKey, innerDict in scores.items() for innerKey, values in innerDict.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = pd.DataFrame(reform).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "del result_df['r2_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mae</th>\n",
       "      <th>rmse</th>\n",
       "      <th>mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">Machine Learning</th>\n",
       "      <th>Polynomial Regression</th>\n",
       "      <td>10.399981</td>\n",
       "      <td>12.369350</td>\n",
       "      <td>27.755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVR Regression</th>\n",
       "      <td>10.365733</td>\n",
       "      <td>12.368533</td>\n",
       "      <td>27.755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Linear Regression</th>\n",
       "      <td>10.318772</td>\n",
       "      <td>12.333228</td>\n",
       "      <td>27.755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision Tree Regression</th>\n",
       "      <td>10.300870</td>\n",
       "      <td>12.324597</td>\n",
       "      <td>27.755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest Regression</th>\n",
       "      <td>10.412176</td>\n",
       "      <td>12.437565</td>\n",
       "      <td>27.755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">Deep Learning</th>\n",
       "      <th>BiDirectional LSTM</th>\n",
       "      <td>10.319810</td>\n",
       "      <td>12.302492</td>\n",
       "      <td>27.755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LSTM AutoEncoder</th>\n",
       "      <td>10.335377</td>\n",
       "      <td>12.328911</td>\n",
       "      <td>27.755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Multi Layer Perceptron</th>\n",
       "      <td>10.316437</td>\n",
       "      <td>12.290038</td>\n",
       "      <td>27.755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">Statistical</th>\n",
       "      <th>Holt-Winters</th>\n",
       "      <td>10.308913</td>\n",
       "      <td>12.333158</td>\n",
       "      <td>27.755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ARIMA</th>\n",
       "      <td>10.306578</td>\n",
       "      <td>12.298804</td>\n",
       "      <td>27.755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AR</th>\n",
       "      <td>10.368587</td>\n",
       "      <td>12.380542</td>\n",
       "      <td>27.755</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 mae       rmse    mean\n",
       "Machine Learning Polynomial Regression     10.399981  12.369350  27.755\n",
       "                 SVR Regression            10.365733  12.368533  27.755\n",
       "                 Linear Regression         10.318772  12.333228  27.755\n",
       "                 Decision Tree Regression  10.300870  12.324597  27.755\n",
       "                 Random Forest Regression  10.412176  12.437565  27.755\n",
       "Deep Learning    BiDirectional LSTM        10.319810  12.302492  27.755\n",
       "                 LSTM AutoEncoder          10.335377  12.328911  27.755\n",
       "                 Multi Layer Perceptron    10.316437  12.290038  27.755\n",
       "Statistical      Holt-Winters              10.308913  12.333158  27.755\n",
       "                 ARIMA                     10.306578  12.298804  27.755\n",
       "                 AR                        10.368587  12.380542  27.755"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
